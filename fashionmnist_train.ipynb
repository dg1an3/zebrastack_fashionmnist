{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0683780d03ee1195a9e1ac19e401b8f6c3447ee82d0b15d335dacfb764b91f68"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "def prepare_images(img_array:np.ndarray, sz=64):\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = [resize(img_array[n], (sz,sz)) for n in range(img_array.shape[0])]\n",
    "    img_array = np.reshape(img_array, (len(img_array),sz,sz,1))\n",
    "    print(img_array.shape)\n",
    "    return img_array\n",
    "\n",
    "train_images = prepare_images(train_images)\n",
    "test_images = prepare_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    \"\"\"\n",
    "    Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    instead of sampling from Q(z|X), sample eps = N(0,I) \n",
    "        then z = z_mean + sqrt(var)*eps    \n",
    "    # Arguments\n",
    "        args (tensor tuple): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"    \n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    # from tensorflow.keras import backend as K\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 64 # train_images.shape[1] * 2\n",
    "print(sz)\n",
    "use_mse = True\n",
    "\n",
    "def vae_loss(z_mean, z_log_var, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute VAE loss, using either mse or crossentropy.\n",
    "    # Arguments\n",
    "        z_mean: mean of Q(z|X)\n",
    "        z_log_var: log variance of Q(z|X)\n",
    "        y_true, y_pred: truth and predicated values\n",
    "    # Returns\n",
    "        loss value\n",
    "    \"\"\"\n",
    "    img_pixels = sz * sz\n",
    "    if use_mse:\n",
    "        match_loss = keras.losses.mse(K.flatten(y_true), K.flatten(y_pred)) * img_pixels\n",
    "    else:\n",
    "        match_loss = binary_crossentropy(K.flatten(y_true), K.flatten(y_pred)) * img_pixels\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean(match_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "act_func = 'softplus' # or 'relu'\n",
    "cit_decimate = False\n",
    "locally_connected_channels = 2\n",
    "latent_dim = 8\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "K.clear_session()\n",
    "\n",
    "def create_encoder():\n",
    "    \"\"\" creates the encoder side of the autoencoder, for the parameters sz and latent_dim\n",
    "    # Static parameters\n",
    "        sz (int): sz x sz input\n",
    "        latent_dim (int): gaussian dimensions\n",
    "        locally_connected_channels = 2\n",
    "    # Arguments\n",
    "        <none>\n",
    "    # Returns\n",
    "        retina: the input layer\n",
    "        encoder: the encoder model\n",
    "        shape: shape of last input layer\n",
    "        [z_mean, z_log_var, z]: tensors for latent space\n",
    "    \"\"\"\n",
    "    retina = Input(shape=(sz,sz,1), name='retina_{}'.format(sz))\n",
    "\n",
    "    v1_conv2d = Conv2D(16, (5,5), name='v1_conv2d', activation=act_func, padding='same')(retina)\n",
    "    v1_maxpool = MaxPooling2D((2,2), name='v1_maxpool', padding='same')(v1_conv2d)\n",
    "    v1_dropout = SpatialDropout2D(0.1, name='v1_dropout')(v1_maxpool)\n",
    "\n",
    "    v2_conv2d = Conv2D(16, (3,3), name='v2_conv2d', activation=act_func, padding='same')(v1_dropout)\n",
    "    v2_maxpool = MaxPooling2D((2,2), name='v2_maxpool', padding='same')(v2_conv2d)\n",
    "\n",
    "    v4_conv2d = Conv2D(32, (3,3), name='v4_conv2d', activation=act_func, padding='same')(v2_maxpool)\n",
    "    v4_maxpool = MaxPooling2D((2,2), name='v4_maxpool', padding='same')(v4_conv2d)\n",
    "\n",
    "    pit_conv2d = Conv2D(32, (3,3), name='pit_conv2d', activation=act_func, padding='same')(v4_maxpool)\n",
    "    # pit_maxpool = MaxPooling2D((2,2), name='pit_maxpool', padding='same')(pit_conv2d)\n",
    "\n",
    "    cit_conv2d = Conv2D(64, (3,3), name='cit_conv2d', activation=act_func, padding='same')(pit_conv2d)\n",
    "    cit_out = cit_conv2d\n",
    "\n",
    "    ait_local = LocallyConnected2D(locally_connected_channels, (3,3), name='ait_local', activation=act_func)(cit_out)\n",
    "    # ait_padding = ZeroPadding2D(padding=(1,1), name='ait_padding')(ait_local)\n",
    "    # x = MaxPooling2D((2,2), padding='same', name='ait_maxpool')(ait_padding)\n",
    "\n",
    "    ait_regular = ActivityRegularization(l1=0.0e-4, l2=0.0e-4, name='ait_regular')(ait_local)\n",
    "\n",
    "    # shape info needed to build decoder model\n",
    "    shape = K.int_shape(ait_regular)\n",
    "    # print(shape)\n",
    "\n",
    "    # generate latent vector Q(z|X)\n",
    "    pulvinar_flatten = Flatten(name='pulvinar_flatten')(ait_regular)\n",
    "    pulvinar_dense = Dense(latent_dim, activation=act_func, name='pulvinar_dense')(pulvinar_flatten)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(pulvinar_dense)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(pulvinar_dense)\n",
    "\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    encoder = Model(retina, [z_mean, z_log_var, z], name='v1_to_pulvinar_encoder')\n",
    "    encoder.summary()\n",
    "    \n",
    "    return retina, encoder, shape, [z_mean, z_log_var, z]\n",
    "\n",
    "retina, encoder, shape, [z_mean, z_log_var, z] = create_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_decoder(shape):\n",
    "    \"\"\" creates the decoder side of the autoencoder, given the input shape\n",
    "    # Static parameters\n",
    "        sz (int): sz x sz input\n",
    "        latent_dim (int): gaussian dimensions\n",
    "        locally_connected_channels = 2\n",
    "    # Arguments\n",
    "        shape: first input layer shape\n",
    "    # Returns\n",
    "        decoder: the decoder model\n",
    "    \"\"\"    \n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    pulvinar_dense_back = Dense(shape[1] * shape[2] * shape[3], name='pulvinar_dense_back', \n",
    "                                activation=act_func)(latent_inputs)\n",
    "    pulvinar_antiflatten = Reshape((shape[1], shape[2], shape[3]), name='pulvinar_antiflatten')(pulvinar_dense_back)\n",
    "\n",
    "    ait_padding_back = ZeroPadding2D(padding=(1,1), name='ait_padding_back')(pulvinar_antiflatten)\n",
    "    ait_local_back = LocallyConnected2D(locally_connected_channels, (3,3), name='ait_local_back', \n",
    "                                        activation=act_func)(ait_padding_back)\n",
    "\n",
    "    cit_padding_back = ZeroPadding2D(padding=(1,1), name='cit_padding_back')(ait_local_back)\n",
    "    ait_out_back = cit_padding_back\n",
    "\n",
    "    cit_conv2d_trans = Conv2DTranspose(64, (3,3), name='cit_conv2d_trans', activation=act_func, padding='same')(ait_out_back)\n",
    "    # cit_upsample_back = UpSampling2D((2,2), name='cit_upsample_back')(cit_conv2d_trans)\n",
    "\n",
    "    pit_conv2d_trans = Conv2DTranspose(32, (3,3), name='pit_conv2d_trans', activation=act_func, padding='same')(cit_conv2d_trans)\n",
    "    # pit_upsample_back = UpSampling2D((2,2), name='pit_upsample_back')(pit_conv2d_trans)\n",
    "\n",
    "    v4_conv2d_trans = Conv2DTranspose(32, (3,3), name='v4_conv2d_trans', activation=act_func, padding='same')(pit_conv2d_trans)\n",
    "    v4_upsample_back = UpSampling2D((2,2), name='v4_upsample_back')(v4_conv2d_trans)\n",
    "\n",
    "    v2_conv2d_trans = Conv2DTranspose(16, (3,3), name='v2_conv2d_trans', activation=act_func, padding='same')(v4_upsample_back)\n",
    "    v2_upsample_back = UpSampling2D((2,2), name='v2_upsample_back')(v2_conv2d_trans)\n",
    "\n",
    "    v1_conv2d_5x5_back = Conv2D(1, (5,5), name='v1_conv2d_5x5_back', activation='sigmoid', padding='same')(v2_upsample_back)\n",
    "    v1_upsample_back = UpSampling2D((2,2), name='v1_upsample_back')(v1_conv2d_5x5_back)\n",
    "\n",
    "    decoder = Model(latent_inputs, v1_upsample_back, name='pulvinar_to_v1_decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    return decoder\n",
    "\n",
    "decoder = create_decoder(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_autoencoder():\n",
    "    \"\"\" create the full autoencoder\n",
    "    # Arguments\n",
    "        <none>\n",
    "    # Returns\n",
    "        encoder: the encoder model\n",
    "        decoder: the decoder model\n",
    "        autoencoder: full model\n",
    "    \"\"\"    \n",
    "    retina, encoder, shape, prob_model = create_encoder()\n",
    "    decoder = create_decoder(shape)\n",
    "    \n",
    "    autoencoder_output = decoder(encoder(retina)[2])\n",
    "    autoencoder = Model(retina, autoencoder_output, name='v1_to_pulvinar_vae')\n",
    "\n",
    "    # now compile with the optimizer VAE loss function\n",
    "    optimizer = 'adadelta'\n",
    "    [z_mean, z_log_var, z] = prob_model\n",
    "    autoencoder.compile(optimizer=optimizer, loss=lambda y_true, y_pred: vae_loss(z_mean, z_log_var, y_true, y_pred))\n",
    "    autoencoder.summary()\n",
    "        \n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "encoder, decoder, autoencoder = create_autoencoder()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "autoencoder.fit(train_images, train_images, epochs=128, batch_size=16, shuffle=True, \n",
    "                validation_data=(test_images, test_images),\n",
    "                callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}